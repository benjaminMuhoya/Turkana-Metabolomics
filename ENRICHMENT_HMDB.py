#!/usr/bin/env python3
"""
ENRICHMENT_HMDB.py  â€“  master runner (2025-07-31 patch 2)

Usage
-----
    python ENRICHMENT_HMDB.py                # classic run
    python ENRICHMENT_HMDB.py --use_ontology # fold in depth-4 subclasses

Pipeline
--------
0.  Rename_to_HMDB.py  â†’  HILIC_HMDB_Residualized_FINAL.csv
1.  Parse HMDB XML â†’ build pathway + synonym map
2.  Match user-side metabolites to HMDB pathways
3.  (opt) ANNOTATE_THE_REST.py â†’ merge depth-4 subclasses as â€œCHEM:<label>â€
4.  Save user_matched_HMDB_pathways.tsv
5.  STATISTICS_ENRICHMENT.py â†’ ANOVA, enrichment, figures
"""
# â”€â”€ imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import argparse, subprocess, sys, pandas as pd, xml.etree.ElementTree as ET
from pathlib import Path

# â”€â”€ CLI flag â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
parser = argparse.ArgumentParser(
    description="Residualize âœ (opt) ontology âœ stats")
parser.add_argument("--use_ontology", action="store_true",
                    help="Merge depth-4 subclasses from ANNOTATE_THE_REST.py")
args = parser.parse_args()

# â”€â”€ 0. residualization â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nâ¤ Running Rename_to_HMDB.py â€¦")
subprocess.run([sys.executable, "Rename_to_HMDB.py"], check=True)
print("âœ… Residualized data ready.\n")

# â”€â”€ 1. load residualized data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_FILE = "HILIC_HMDB_Residualized_FINAL.csv"
XML_FILE  = "hmdb_metabolites_ALL_OF_THEM.xml"

df        = pd.read_csv(DATA_FILE)
hmdb_ids  = df.columns[2:]                       # first 2 cols = IDs + group

print(f"ğŸ“Š {df.shape[0]} samples â€¢ {len(hmdb_ids)} metabolites")
print("\nğŸ‘¥ Lifestyle counts:")
print(df['MW_scores_lifestyle_2'].value_counts().to_string())

# â”€â”€ 2. parse HMDB XML â†’ pathway & synonym maps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nğŸ” Building pathway & synonym maps from HMDB XML â€¦")
URI  = "{http://www.hmdb.ca}"                    # namespace URI
ctx  = ET.iterparse(XML_FILE, events=("end",))

hmdb_pathway_map, synonym_map = {}, {}
for _, elem in ctx:
    if elem.tag.endswith("metabolite"):
        acc = elem.findtext(f"{URI}accession")
        if not acc:
            elem.clear(); continue

        # pathways
        pws = [pw.findtext(f"{URI}name").strip()
               for pw in elem.findall(f".//{URI}pathway")
               if pw.findtext(f"{URI}name")]
        hmdb_pathway_map[acc] = list(dict.fromkeys(pws))

        # synonyms (incl. common name)
        common = elem.findtext(f"{URI}name")
        if common:
            synonym_map[common.lower()] = acc
        for syn in elem.findall(f".//{URI}synonym"):
            if syn.text:
                synonym_map[syn.text.strip().lower()] = acc

        elem.clear()

print(f"âœ… {len(hmdb_pathway_map)} metabolites parsed")
print(f"âœ… {len(synonym_map)} synonyms collected")

# metabolites lacking pathways
no_pw = [acc for acc, pws in hmdb_pathway_map.items() if not pws]
pd.Series(no_pw, name="HMDB_ID").to_csv("hmdb_no_pathways.tsv",
                                        sep="\t", index=False)
print(f"âš ï¸  {len(no_pw)} metabolites lack pathways (logged).")

# â”€â”€ 3. match user metabolites to HMDB accessions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
matched, unmatched = [], []
for h in hmdb_ids:
    if h in hmdb_pathway_map:
        matched.append(h)
    else:
        acc = synonym_map.get(h.lower())
        (matched if acc in hmdb_pathway_map else unmatched).append(acc or h)

print(f"ğŸ”— Matched {len(matched)} / {len(hmdb_ids)} metabolites")
print(f"âŒ Unmatched: {len(unmatched)}")

out_df = pd.DataFrame(
    {"HMDB_ID": m,
     "Pathways": "; ".join(hmdb_pathway_map[m])}
    for m in matched
)
out_df.to_csv("user_matched_HMDB_pathways.tsv", sep="\t", index=False)
print("ğŸ“ Saved user_matched_HMDB_pathways.tsv")

# â”€â”€ 4. optional ontology harvest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if args.use_ontology and no_pw:
    print("\nâ¤ Running ANNOTATE_THE_REST.py â€¦")
    subprocess.run([sys.executable, "ANNOTATE_THE_REST.py"], check=True)

    lvl4 = (pd.read_csv("hmdb_level4_mapping.tsv", sep="\t")
              .dropna(subset=["chem_subclass_lvl4"])
              .rename(columns={"chem_subclass_lvl4": "Pathways"}))
    lvl4["Pathways"] = "CHEM:" + lvl4["Pathways"]          # tag origin
    new_rows = lvl4[~lvl4.HMDB_ID.isin(out_df.HMDB_ID)]

    out_df = pd.concat([out_df, new_rows], ignore_index=True)
    out_df.to_csv("user_matched_HMDB_pathways.tsv", sep="\t", index=False)
    print(f"âœ… Added {len(new_rows)} depth-4 subclass rows "
          f"(total {len(out_df)})")
else:
    print("â„¹ï¸  Ontology step skipped.")

# â”€â”€ 5. fallback classification (optional QC) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if no_pw:
    fb = {}
    for _, elem in ET.iterparse(XML_FILE, events=("end",)):
        if elem.tag.endswith("metabolite"):
            acc = elem.findtext(f"{URI}accession")
            if acc in no_pw:
                cls = [c.text for c in elem.findall(f".//{URI}classification") if c.text]
                fb[acc] = cls or ["<no classification>"]
            elem.clear()
    pd.DataFrame.from_dict(fb, orient="index", columns=["Classifications"])\
      .to_csv("hmdb_fallback_classification.tsv", sep="\t")
    print("ğŸ—‚  Wrote hmdb_fallback_classification.tsv")

# â”€â”€ 6. run statistics & enrichment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nâ¤ Running STATISTICS_ENRICHMENT.py â€¦")
subprocess.run([sys.executable, "STATISTICS_ENRICHMENT.py"], check=True)

print("\nğŸ‰ Pipeline complete â€“ check pathway_enrichment_results.tsv & figures!")

